{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/amitjain/workspace/data/tasks/sgd/albert_base_vocaborg/single_domain/checkpoint/model.ckpt-2000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_vars = tf.train.list_variables(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bert/embeddings/LayerNorm/beta', [128]),\n",
       " ('bert/embeddings/LayerNorm/beta/adam_m', [128]),\n",
       " ('bert/embeddings/LayerNorm/beta/adam_v', [128]),\n",
       " ('bert/embeddings/LayerNorm/gamma', [128]),\n",
       " ('bert/embeddings/LayerNorm/gamma/adam_m', [128]),\n",
       " ('bert/embeddings/LayerNorm/gamma/adam_v', [128]),\n",
       " ('bert/embeddings/position_embeddings', [512, 128]),\n",
       " ('bert/embeddings/position_embeddings/adam_m', [512, 128]),\n",
       " ('bert/embeddings/position_embeddings/adam_v', [512, 128]),\n",
       " ('bert/embeddings/token_type_embeddings', [2, 128]),\n",
       " ('bert/embeddings/token_type_embeddings/adam_m', [2, 128]),\n",
       " ('bert/embeddings/token_type_embeddings/adam_v', [2, 128]),\n",
       " ('bert/embeddings/word_embeddings', [30000, 128]),\n",
       " ('bert/embeddings/word_embeddings/adam_m', [30000, 128]),\n",
       " ('bert/embeddings/word_embeddings/adam_v', [30000, 128]),\n",
       " ('bert/encoder/embedding_hidden_mapping_in/bias', [768]),\n",
       " ('bert/encoder/embedding_hidden_mapping_in/bias/adam_m', [768]),\n",
       " ('bert/encoder/embedding_hidden_mapping_in/bias/adam_v', [768]),\n",
       " ('bert/encoder/embedding_hidden_mapping_in/kernel', [128, 768]),\n",
       " ('bert/encoder/embedding_hidden_mapping_in/kernel/adam_m', [128, 768]),\n",
       " ('bert/encoder/embedding_hidden_mapping_in/kernel/adam_v', [128, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta', [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma', [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel/adam_m',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel/adam_v',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel/adam_m',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel/adam_v',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel/adam_m',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel/adam_v',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel/adam_m',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel/adam_v',\n",
       "  [768, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias',\n",
       "  [3072]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias/adam_m',\n",
       "  [3072]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias/adam_v',\n",
       "  [3072]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel',\n",
       "  [768, 3072]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel/adam_m',\n",
       "  [768, 3072]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel/adam_v',\n",
       "  [768, 3072]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias/adam_m',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias/adam_v',\n",
       "  [768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel',\n",
       "  [3072, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel/adam_m',\n",
       "  [3072, 768]),\n",
       " ('bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel/adam_v',\n",
       "  [3072, 768]),\n",
       " ('bert/pooler/dense/bias', [768]),\n",
       " ('bert/pooler/dense/bias/adam_m', [768]),\n",
       " ('bert/pooler/dense/bias/adam_v', [768]),\n",
       " ('bert/pooler/dense/kernel', [768, 768]),\n",
       " ('bert/pooler/dense/kernel/adam_m', [768, 768]),\n",
       " ('bert/pooler/dense/kernel/adam_v', [768, 768]),\n",
       " ('categorical_slot_status_projection_1/bias', [768]),\n",
       " ('categorical_slot_status_projection_1/bias/adam_m', [768]),\n",
       " ('categorical_slot_status_projection_1/bias/adam_v', [768]),\n",
       " ('categorical_slot_status_projection_1/kernel', [1536, 768]),\n",
       " ('categorical_slot_status_projection_1/kernel/adam_m', [1536, 768]),\n",
       " ('categorical_slot_status_projection_1/kernel/adam_v', [1536, 768]),\n",
       " ('categorical_slot_status_projection_2/bias', [3]),\n",
       " ('categorical_slot_status_projection_2/bias/adam_m', [3]),\n",
       " ('categorical_slot_status_projection_2/bias/adam_v', [3]),\n",
       " ('categorical_slot_status_projection_2/kernel', [768, 3]),\n",
       " ('categorical_slot_status_projection_2/kernel/adam_m', [768, 3]),\n",
       " ('categorical_slot_status_projection_2/kernel/adam_v', [768, 3]),\n",
       " ('categorical_slot_status_utterance_proj/bias', [768]),\n",
       " ('categorical_slot_status_utterance_proj/bias/adam_m', [768]),\n",
       " ('categorical_slot_status_utterance_proj/bias/adam_v', [768]),\n",
       " ('categorical_slot_status_utterance_proj/kernel', [768, 768]),\n",
       " ('categorical_slot_status_utterance_proj/kernel/adam_m', [768, 768]),\n",
       " ('categorical_slot_status_utterance_proj/kernel/adam_v', [768, 768]),\n",
       " ('categorical_slot_values_projection_1/bias', [768]),\n",
       " ('categorical_slot_values_projection_1/bias/adam_m', [768]),\n",
       " ('categorical_slot_values_projection_1/bias/adam_v', [768]),\n",
       " ('categorical_slot_values_projection_1/kernel', [1536, 768]),\n",
       " ('categorical_slot_values_projection_1/kernel/adam_m', [1536, 768]),\n",
       " ('categorical_slot_values_projection_1/kernel/adam_v', [1536, 768]),\n",
       " ('categorical_slot_values_projection_2/bias', [1]),\n",
       " ('categorical_slot_values_projection_2/bias/adam_m', [1]),\n",
       " ('categorical_slot_values_projection_2/bias/adam_v', [1]),\n",
       " ('categorical_slot_values_projection_2/kernel', [768, 1]),\n",
       " ('categorical_slot_values_projection_2/kernel/adam_m', [768, 1]),\n",
       " ('categorical_slot_values_projection_2/kernel/adam_v', [768, 1]),\n",
       " ('categorical_slot_values_utterance_proj/bias', [768]),\n",
       " ('categorical_slot_values_utterance_proj/bias/adam_m', [768]),\n",
       " ('categorical_slot_values_utterance_proj/bias/adam_v', [768]),\n",
       " ('categorical_slot_values_utterance_proj/kernel', [768, 768]),\n",
       " ('categorical_slot_values_utterance_proj/kernel/adam_m', [768, 768]),\n",
       " ('categorical_slot_values_utterance_proj/kernel/adam_v', [768, 768]),\n",
       " ('global_step', []),\n",
       " ('intents_projection_1/bias', [768]),\n",
       " ('intents_projection_1/bias/adam_m', [768]),\n",
       " ('intents_projection_1/bias/adam_v', [768]),\n",
       " ('intents_projection_1/kernel', [1536, 768]),\n",
       " ('intents_projection_1/kernel/adam_m', [1536, 768]),\n",
       " ('intents_projection_1/kernel/adam_v', [1536, 768]),\n",
       " ('intents_projection_2/bias', [1]),\n",
       " ('intents_projection_2/bias/adam_m', [1]),\n",
       " ('intents_projection_2/bias/adam_v', [1]),\n",
       " ('intents_projection_2/kernel', [768, 1]),\n",
       " ('intents_projection_2/kernel/adam_m', [768, 1]),\n",
       " ('intents_projection_2/kernel/adam_v', [768, 1]),\n",
       " ('intents_utterance_proj/bias', [768]),\n",
       " ('intents_utterance_proj/bias/adam_m', [768]),\n",
       " ('intents_utterance_proj/bias/adam_v', [768]),\n",
       " ('intents_utterance_proj/kernel', [768, 768]),\n",
       " ('intents_utterance_proj/kernel/adam_m', [768, 768]),\n",
       " ('intents_utterance_proj/kernel/adam_v', [768, 768]),\n",
       " ('noncat_spans_layer_1/bias', [768]),\n",
       " ('noncat_spans_layer_1/bias/adam_m', [768]),\n",
       " ('noncat_spans_layer_1/bias/adam_v', [768]),\n",
       " ('noncat_spans_layer_1/kernel', [1536, 768]),\n",
       " ('noncat_spans_layer_1/kernel/adam_m', [1536, 768]),\n",
       " ('noncat_spans_layer_1/kernel/adam_v', [1536, 768]),\n",
       " ('noncat_spans_layer_2/bias', [2]),\n",
       " ('noncat_spans_layer_2/bias/adam_m', [2]),\n",
       " ('noncat_spans_layer_2/bias/adam_v', [2]),\n",
       " ('noncat_spans_layer_2/kernel', [768, 2]),\n",
       " ('noncat_spans_layer_2/kernel/adam_m', [768, 2]),\n",
       " ('noncat_spans_layer_2/kernel/adam_v', [768, 2]),\n",
       " ('noncategorical_slot_status_projection_1/bias', [768]),\n",
       " ('noncategorical_slot_status_projection_1/bias/adam_m', [768]),\n",
       " ('noncategorical_slot_status_projection_1/bias/adam_v', [768]),\n",
       " ('noncategorical_slot_status_projection_1/kernel', [1536, 768]),\n",
       " ('noncategorical_slot_status_projection_1/kernel/adam_m', [1536, 768]),\n",
       " ('noncategorical_slot_status_projection_1/kernel/adam_v', [1536, 768]),\n",
       " ('noncategorical_slot_status_projection_2/bias', [3]),\n",
       " ('noncategorical_slot_status_projection_2/bias/adam_m', [3]),\n",
       " ('noncategorical_slot_status_projection_2/bias/adam_v', [3]),\n",
       " ('noncategorical_slot_status_projection_2/kernel', [768, 3]),\n",
       " ('noncategorical_slot_status_projection_2/kernel/adam_m', [768, 3]),\n",
       " ('noncategorical_slot_status_projection_2/kernel/adam_v', [768, 3]),\n",
       " ('noncategorical_slot_status_utterance_proj/bias', [768]),\n",
       " ('noncategorical_slot_status_utterance_proj/bias/adam_m', [768]),\n",
       " ('noncategorical_slot_status_utterance_proj/bias/adam_v', [768]),\n",
       " ('noncategorical_slot_status_utterance_proj/kernel', [768, 768]),\n",
       " ('noncategorical_slot_status_utterance_proj/kernel/adam_m', [768, 768]),\n",
       " ('noncategorical_slot_status_utterance_proj/kernel/adam_v', [768, 768]),\n",
       " ('null_intent_embedding', [1, 1, 768]),\n",
       " ('null_intent_embedding/adam_m', [1, 1, 768]),\n",
       " ('null_intent_embedding/adam_v', [1, 1, 768]),\n",
       " ('requested_slots_projection_1/bias', [768]),\n",
       " ('requested_slots_projection_1/bias/adam_m', [768]),\n",
       " ('requested_slots_projection_1/bias/adam_v', [768]),\n",
       " ('requested_slots_projection_1/kernel', [1536, 768]),\n",
       " ('requested_slots_projection_1/kernel/adam_m', [1536, 768]),\n",
       " ('requested_slots_projection_1/kernel/adam_v', [1536, 768]),\n",
       " ('requested_slots_projection_2/bias', [1]),\n",
       " ('requested_slots_projection_2/bias/adam_m', [1]),\n",
       " ('requested_slots_projection_2/bias/adam_v', [1]),\n",
       " ('requested_slots_projection_2/kernel', [768, 1]),\n",
       " ('requested_slots_projection_2/kernel/adam_m', [768, 1]),\n",
       " ('requested_slots_projection_2/kernel/adam_v', [768, 1]),\n",
       " ('requested_slots_utterance_proj/bias', [768]),\n",
       " ('requested_slots_utterance_proj/bias/adam_m', [768]),\n",
       " ('requested_slots_utterance_proj/bias/adam_v', [768]),\n",
       " ('requested_slots_utterance_proj/kernel', [768, 768]),\n",
       " ('requested_slots_utterance_proj/kernel/adam_m', [768, 768]),\n",
       " ('requested_slots_utterance_proj/kernel/adam_v', [768, 768])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fda1dc91c164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary():\n",
    "    model_vars = init_vars\n",
    "    slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
